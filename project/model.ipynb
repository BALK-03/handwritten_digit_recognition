{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape = (28, 28), name = \"Flatten_layer\"),\n",
    "    Dense(units = 128, activation = \"relu\", name = \"layer_1\"),\n",
    "    Dense(units = 128, activation = \"relu\", name = \"layer_2\"),\n",
    "    Dense(units = 10, activation = \"softmax\", name = \"layer_3\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Flatten_layer (Flatten)     (None, 784)               0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " layer_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 32s 16ms/step - loss: 0.2592 - accuracy: 0.9250\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 0.1033 - accuracy: 0.9684\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0695 - accuracy: 0.9782\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0532 - accuracy: 0.9836\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0406 - accuracy: 0.9868\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0324 - accuracy: 0.9893\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0243 - accuracy: 0.9917\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0198 - accuracy: 0.9932\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0159 - accuracy: 0.9945\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0130 - accuracy: 0.9954\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0129 - accuracy: 0.9954\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0105 - accuracy: 0.9965\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0089 - accuracy: 0.9967\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0097 - accuracy: 0.9967\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0084 - accuracy: 0.9970\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0051 - accuracy: 0.9983\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0099 - accuracy: 0.9969\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0065 - accuracy: 0.9977\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0070 - accuracy: 0.9976\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0081 - accuracy: 0.9974\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0067 - accuracy: 0.9977\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0047 - accuracy: 0.9983\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0043 - accuracy: 0.9988\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0061 - accuracy: 0.9981\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0017 - accuracy: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2997e389810>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, epochs = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2299 - accuracy: 0.9771\n",
      "The loss of the model is: 0.2298717051744461\n",
      "The accuracy of the model: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"The loss of the model is: {loss}\")\n",
    "print(f\"The accuracy of the model: {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Flatten_layer_input with unsupported characters which will be renamed to flatten_layer_input in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
